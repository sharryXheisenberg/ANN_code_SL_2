{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13be058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Error 0.5000553523137073\n",
      "Epoch 1000: Error 0.4999182467732897\n",
      "Epoch 2000: Error 0.4996238867690278\n",
      "Epoch 3000: Error 0.4983370149832837\n",
      "Epoch 4000: Error 0.4864684380377371\n",
      "Epoch 5000: Error 0.41601835208284377\n",
      "Epoch 6000: Error 0.34637547818925574\n",
      "Epoch 7000: Error 0.31482255008602533\n",
      "Epoch 8000: Error 0.2994208027316783\n",
      "Epoch 9000: Error 0.2905472832161088\n",
      "\n",
      "Output from neural network after 10,000 epochs: \n",
      "Predicted XOR\t Approx output XOR\n",
      "0.05677834258550272------------>0\n",
      "0.4977336978496097------------>0\n",
      "0.9287452895234409------------>1\n",
      "0.5088288593483903------------>1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class XORNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Random weights and bias initialization\n",
    "        self.h_w = np.random.uniform(-0.5,0.5,(self.input_size, self.hidden_size)) # hidden_weights -> h_w\n",
    "        self.h_b = np.random.uniform(-0.5,0.5,(1, self.hidden_size))               # hidden_bias - > h_b\n",
    "        self.o_w = np.random.uniform(-0.5,0.5,(self.hidden_size, self.output_size)) # output_weight - o_w\n",
    "        self.o_b = np.random.uniform(-0.5,0.5,(1, self.output_size))                # ouput_bias -> o_b\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_propagation(self, inputs):\n",
    "        hidden_layer_activation = np.dot(inputs, self.h_w) + self.h_b\n",
    "        hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
    "        \n",
    "        output_layer_activation = np.dot(hidden_layer_output, self.o_w) + self.o_b\n",
    "        predicted_output = self.sigmoid(output_layer_activation)\n",
    "        \n",
    "        return predicted_output, hidden_layer_output\n",
    "    \n",
    "    def backward_propagation(self, inputs, predicted_output, hidden_layer_output, expected_output):\n",
    "        error = expected_output - predicted_output\n",
    "        d_predicted_output = error * self.sigmoid_derivative(predicted_output) \n",
    "        \n",
    "        error_hidden_layer = d_predicted_output.dot(self.o_w.T)\n",
    "        d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(hidden_layer_output)\n",
    "        \n",
    "        \n",
    "        # Updating Weights and Biases\n",
    "        self.o_w += hidden_layer_output.T.dot(d_predicted_output) * self.learning_rate\n",
    "        self.o_b += np.sum(d_predicted_output, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.h_w += inputs.T.dot(d_hidden_layer) * self.learning_rate\n",
    "        self.h_b += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.learning_rate\n",
    "    \n",
    "    def train(self, inputs, expected_output, epochs):\n",
    "        for epoch\n",
    "        in range(epochs):\n",
    "            predicted_output, hidden_layer_output = self.forward_propagation(inputs)\n",
    "            self.backward_propagation(inputs, predicted_output, hidden_layer_output, expected_output)\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f'Epoch {epoch}: Error {np.mean(np.abs(expected_output - predicted_output))}')\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        predicted_output, _ = self.forward_propagation(inputs)\n",
    "        return predicted_output\n",
    "\n",
    "# Input datasets\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "expected_output = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Hyperparameters\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2, 2, 1\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "# Create and train the neural network\n",
    "xor_nn = XORNeuralNetwork(inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons, learning_rate)\n",
    "xor_nn.train(inputs, expected_output, epochs)\n",
    "\n",
    "# Testing\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \")\n",
    "print(\"Predicted XOR\\t Approx output XOR\")\n",
    "for input_data in inputs:\n",
    "    output = xor_nn.predict(input_data)[0][0]\n",
    "    approx_output = 1 if output >= 0.5 else 0\n",
    "    print(f\"{output}------------>{approx_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9baa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR without loss epochs code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab263bc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 58>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Create and train the neural network\u001b[39;00m\n\u001b[0;32m     57\u001b[0m xor_nn \u001b[38;5;241m=\u001b[39m XORNeuralNetwork(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mxor_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted XOR\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Approx output XOR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mXORNeuralNetwork.train\u001b[1;34m(self, inputs, expected_output, epochs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     47\u001b[0m     predicted_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_propagation(inputs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mXORNeuralNetwork.backward_propagation\u001b[1;34m(self, inputs, predicted_output, expected_output)\u001b[0m\n\u001b[0;32m     32\u001b[0m error \u001b[38;5;241m=\u001b[39m expected_output \u001b[38;5;241m-\u001b[39m predicted_output\n\u001b[0;32m     33\u001b[0m d_predicted_output \u001b[38;5;241m=\u001b[39m error \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid_derivative(predicted_output)  \u001b[38;5;66;03m# Element-wise multiplication\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m error_hidden_layer \u001b[38;5;241m=\u001b[39m \u001b[43md_predicted_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_w\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m d_hidden_layer \u001b[38;5;241m=\u001b[39m error_hidden_layer \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_output)  \u001b[38;5;66;03m# Use self.hidden_output\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Updating Weights and Biases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class XORNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Random weights and bias initialization\n",
    "        self.h_w = np.random.uniform(-0.5,0.5,(self.input_size, self.hidden_size))\n",
    "        self.h_b = np.random.uniform(-0.5,0.5,(1, self.hidden_size))\n",
    "        self.o_w = np.random.uniform(-0.5,0.5,(self.hidden_size, self.output_size))\n",
    "        self.o_b = np.random.uniform(-0.5,0.5,(1, self.output_size))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def forward_propagation(self, inputs):\n",
    "        hidden_layer_activation = np.dot(inputs, self.h_w) + self.h_b\n",
    "        hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
    "        \n",
    "        output_layer_activation = np.dot(hidden_layer_output, self.o_w) + self.o_b\n",
    "        predicted_output = self.sigmoid(output_layer_activation)\n",
    "        \n",
    "        return predicted_output\n",
    "    \n",
    "    def backward_propagation(self, inputs, predicted_output, expected_output):\n",
    "        error = expected_output - predicted_output\n",
    "        d_predicted_output = error * self.sigmoid_derivative(predicted_output)  # Element-wise multiplication\n",
    "        \n",
    "        error_hidden_layer = d_predicted_output.dot(self.o_w.T)\n",
    "        d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(self.hidden_output)  # Use self.hidden_output\n",
    "        \n",
    "        # Updating Weights and Biases\n",
    "        self.o_w += self.hidden_output.T.dot(d_predicted_output) * self.learning_rate\n",
    "        self.o_b += np.sum(d_predicted_output, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.h_w += inputs.T.dot(d_hidden_layer) * self.learning_rate\n",
    "        self.h_b += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    \n",
    "    def train(self, inputs, expected_output, epochs):\n",
    "        for _ in range(epochs):\n",
    "            predicted_output = self.forward_propagation(inputs)\n",
    "            self.backward_propagation(inputs, predicted_output, expected_output)\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        return self.forward_propagation(inputs)\n",
    "\n",
    "# Input datasets\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Create and train the neural network\n",
    "xor_nn = XORNeuralNetwork(2, 2, 1, 0.1)\n",
    "xor_nn.train(inputs, inputs, 10000)\n",
    "\n",
    "# Testing\n",
    "print(\"Predicted XOR\\t Approx output XOR\")\n",
    "for input_data in inputs:\n",
    "    output = xor_nn.predict(input_data)[0][0]\n",
    "    approx_output = 1 if output >= 0.5 else 0\n",
    "    print(f\"{output}------------>{approx_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0662a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor without class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43abba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output from neural network after 10,000 epochs: \n",
      "Predicted XOR\t Approx output XOR\n",
      "[0.04911966]------------>0\n",
      "[0.94826032]------------>1\n",
      "[0.49666818]------------>0\n",
      "[0.50427645]------------>1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Input datasets\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "expected_output = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2, 2, 1\n",
    "\n",
    "# Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n",
    "hidden_bias = np.random.uniform(size=(1, hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1, outputLayerNeurons))\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs, hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    output_layer_activation = np.dot(hidden_layer_output, output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    # Backpropagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Updating Weights and Biases\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \")\n",
    "print(\"Predicted XOR\\t Approx output XOR\")\n",
    "for output in predicted_output:\n",
    "    approx_output = 1 if output >= 0.5 else 0\n",
    "    print(f\"{output}------------>{approx_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564edff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb97de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xor:\n",
    "    def __init__(self,input_size,hidden_size,output_size,lr):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.h_w = np.random.uniform(-0.5,0.5,(self.input_size,self.hidden_size))\n",
    "        self.h_o = np.random.uniform(-0.5,0.5,(1,self.hidden_size))  # hidden bias\n",
    "        self.o_w = np.random.uniform(-0.5,0.5,(self.hidden_size,self.output_size))\n",
    "        self.o_h = np.random.uniform(-0.5,0.5,(1,self.output_size))  # output bias\n",
    "        \n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+ np.exp(-x))\n",
    "    \n",
    "    def sig_der(self,x):\n",
    "        return x*(1-x)\n",
    "        \n",
    "        \n",
    "    def f_P(self,inputs):\n",
    "        hid_lay_act = np.dot(inputs,self.h_w) + self.h_o\n",
    "        hid_lay_out = self.sigmoid(hid_lay_act)\n",
    "        \n",
    "        out_lay_act = np.dot(hid_lay_out,self.o_w) + self.o_h\n",
    "        predicted_output = self.sigmoid(out_lay_act)\n",
    "        \n",
    "        return predicted_output , hid_lay_out\n",
    "    \n",
    "    def b_p(self,inputs , predicted_output ,hid_lay_out,excepted_output):\n",
    "        e = excepted_output - predicted_output\n",
    "        d_predicted_output = e*self.sig_der(predicted_output)\n",
    "        \n",
    "        error_hid_lay = d_predicted_output.dot(self.o_w.T)\n",
    "        d_hidden_layer = error_hid_lay*self.sig_der(hid_lay_out)\n",
    "        \n",
    "        \n",
    "        # change the weights and biases\n",
    "        \n",
    "        self.o_w+=hid_lay_out.T.dot(d_predicted_output)*self.lr\n",
    "        self.o_h+=np.sum(d_predicted_output,axis=0,keepdims=True)*self.lr\n",
    "        self.h_w+=inputs.T.dot(d_hidden_layer)*self.lr\n",
    "        self.h_o+=np.sum(d_hidden_layer,axis=0,keepdims=True)*self.lr\n",
    "        # what is the meaning and function of 'keepdims=True'\n",
    "        \n",
    "    def train(self,inputs,execpted_output,epochs):\n",
    "        for epoch in range(epochs):\n",
    "            predicted_output , hid_lay_out = self.f_P(inputs)\n",
    "            self.b_p(inputs,predicted_output,hid_lay_out , excepted_output)\n",
    "            if epoch % 1000==0:\n",
    "                print(f'Epoch{epoch}: Error {np.mean(np.abs(excepted_output - predicted_output))}')\n",
    "                \n",
    "        \n",
    "    def predict(self,inputs):\n",
    "        predicted_output  , _ = self.f_P(inputs)\n",
    "        return predicted_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c19d6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0: Error 0.4999463046083989\n",
      "Epoch1000: Error 0.4999164300717439\n",
      "Epoch2000: Error 0.49978409345063224\n",
      "Epoch3000: Error 0.49907380899395415\n",
      "Epoch4000: Error 0.4899419848201241\n",
      "Epoch5000: Error 0.43011489860440344\n",
      "Epoch6000: Error 0.3696627759171602\n",
      "Epoch7000: Error 0.25723940963154146\n",
      "Epoch8000: Error 0.1431253726235467\n",
      "Epoch9000: Error 0.10034094288646278\n",
      "Predicted XOR \t approx XOR\n",
      "0.06516423943461717----------------->0\n",
      "0.9236148032848907----------------->1\n",
      "0.923152267258373----------------->1\n",
      "0.10065037937252877----------------->0\n"
     ]
    }
   ],
   "source": [
    "# inputs \n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "excepted_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "\n",
    "ip_neurons  , hid_neurons , op_neurons = 2,2,1\n",
    "lr = 0.1\n",
    "epochs=10000\n",
    "\n",
    "xor = Xor(ip_neurons, hid_neurons , op_neurons , lr)\n",
    "xor.train(inputs,excepted_output , epochs)\n",
    "\n",
    "\n",
    "# testing\n",
    "\n",
    "print(\"Predicted XOR \\t     approx XOR\")\n",
    "for input_data in inputs:\n",
    "    output = xor.predict(input_data)[0][0]\n",
    "    approx_output = 1 if output>=0.5 else 0\n",
    "    print(f\"{output}----------------->{approx_output}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5ce543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38850ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xor:\n",
    "    def __init__(self,input_size , hidden_size,output_size , lr):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.h_w = np.random.uniform(-0.5 , 0.5,(self.input_size , self.hidden_size))\n",
    "        self.h_b = np.random.uniform(-0.5,0.5 ,(1 , self.hidden_size))\n",
    "        self.o_w = np.random.uniform(-0.5 , 0.5 ,(self.hidden_size,self.output_size))\n",
    "        self.o_b = np.random.uniform(-0.5, 0.5 , (1,self.output_size))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sig_der(self,x):\n",
    "        return x*(1-x)\n",
    "    \n",
    "    def f_p(self,inputs):\n",
    "        hid_lay_act = np.dot(inputs,self.h_w)+self.h_b\n",
    "        hidden_layer_output = self.sigmoid(hid_lay_act)\n",
    "        \n",
    "        output_lay_act = np.dot(hidden_layer_output,self.o_w) + self.o_b\n",
    "        predicted_output = self.sigmoid(output_lay_act)\n",
    "        \n",
    "        return predicted_output , hidden_layer_output\n",
    "    \n",
    "    def b_p(self,inputs ,predicted_output, hidden_layer_output   , excepted_output):\n",
    "        e = excepted_output - predicted_output\n",
    "        d_predicted_output = e*self.sig_der(predicted_output)  # deltaw\n",
    "        \n",
    "        hid_lay_error = d_predicted_output.dot(self.o_w.T)\n",
    "        d_hid_lay = hid_lay_error*self.sig_der(hidden_layer_output) # delta h\n",
    "        \n",
    "        \n",
    "        self.o_w+=hidden_layer_output.T.dot(d_predicted_output)*self.lr\n",
    "        self.o_b+=np.sum(d_predicted_output,axis=0,keepdims=True)*self.lr\n",
    "        self.h_w+=inputs.T.dot(d_hid_lay)*self.lr\n",
    "        self.h_b+=np.sum(d_hid_lay,axis=0,keepdims=True)*self.lr\n",
    "        \n",
    "        \n",
    "    def train(self,inputs , excepted_output,epochs):\n",
    "        for epoch in range(epochs):\n",
    "            predicted_output , hidden_layer_output = self.f_p(inputs)\n",
    "            self.b_p(inputs ,predicted_output , hidden_layer_output , excepted_output)\n",
    "            if epoch%1000 == 0 :\n",
    "                print(f'Epoch {epoch} : Error {np.mean(np.abs(excepted_output - predicted_output))}')\n",
    "                \n",
    "    \n",
    "    def predict(self,inputs):\n",
    "        predicted_output , _ = self.f_p(inputs)\n",
    "        return predicted_output\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd483ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Error 0.49984112546785364\n",
      "Epoch 1000 : Error 0.4993925107254985\n",
      "Epoch 2000 : Error 0.4948597828300739\n",
      "Epoch 3000 : Error 0.45320592871625665\n",
      "Epoch 4000 : Error 0.3938590078339377\n",
      "Epoch 5000 : Error 0.3599993495469975\n",
      "Epoch 6000 : Error 0.22185788230159825\n",
      "Epoch 7000 : Error 0.12824329531570766\n",
      "Epoch 8000 : Error 0.09357476796775721\n",
      "Epoch 9000 : Error 0.07594320730465409\n",
      " Predicted XOR \t        approx XOR\n",
      "[[0.05481343]] ---------------->0\n",
      "[[0.93203861]] ---------------->1\n",
      "[[0.93205924]] ---------------->1\n",
      "[[0.0696798]] ---------------->0\n"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "\n",
    "inputs = np.array([[0,0],[0,1] , [1,0] , [1,1]])\n",
    "excepted_output = np.array([[0] , [1] , [1] , [0]])\n",
    "\n",
    "ip_lay_neurons  , hd_lay_neurons , op_lay_neurons = 2 , 2, 1\n",
    "lr = 0.1 \n",
    "epochs = 10000\n",
    "\n",
    "xor = Xor(ip_lay_neurons  , hd_lay_neurons , op_lay_neurons,lr)\n",
    "\n",
    "\n",
    "# create predictions \n",
    "xor.train(inputs , excepted_output , epochs)\n",
    "\n",
    "print(\" Predicted XOR \\t        approx XOR\")\n",
    "\n",
    "for input_data in inputs:\n",
    "    output = xor.predict(input_data)\n",
    "    approx_output = 1 if output >=0.5 else 0\n",
    "    print(f\"{output} ---------------->{approx_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b01ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
