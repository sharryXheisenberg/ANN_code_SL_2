{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313bb71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class names: ['virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_layers, hidden_neurons, output_neurons, threshold=0.5):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.output_neurons = output_neurons\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # Initialize weights and biases for hidden layers\n",
    "        self.weights.append(np.random.randn(hidden_neurons, input_size))\n",
    "        self.biases.append(np.zeros((hidden_neurons, 1)))\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            self.weights.append(np.random.randn(hidden_neurons, hidden_neurons))\n",
    "            self.biases.append(np.zeros((hidden_neurons, 1)))\n",
    "        \n",
    "        # Initialize weights and biases for output layer\n",
    "        self.weights.append(np.random.randn(output_neurons, hidden_neurons))\n",
    "        self.biases.append(np.zeros((output_neurons, 1)))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=0, keepdims=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        activations = []\n",
    "        input_data = x.T  # Transpose the input data\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.weights[i], input_data) + self.biases[i]\n",
    "            if i == len(self.weights) - 1:\n",
    "                activation = self.softmax(z)\n",
    "            else:\n",
    "                activation = self.relu(z)\n",
    "            activations.append(activation)\n",
    "            input_data = activation\n",
    "        return activations\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        activations = self.forward(x)\n",
    "        predictions = activations[-1].T  # Transpose the output back to the original shape\n",
    "        return (predictions >= self.threshold).astype(int)\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Normalize input data\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Define neural network parameters\n",
    "input_size = X.shape[1]\n",
    "hidden_layers = 1\n",
    "hidden_neurons = 100\n",
    "output_neurons = 3  # Number of classes in Iris dataset\n",
    "threshold = 0.5  # Threshold for binary classification\n",
    "\n",
    "# Create neural network\n",
    "nn = NeuralNetwork(input_size, hidden_layers, hidden_neurons, output_neurons, threshold)\n",
    "\n",
    "# Perform prediction\n",
    "predictions = nn.predict(X)\n",
    "\n",
    "# Convert predictions to class names\n",
    "class_names = ['setosa', 'versicolor', 'virginica']\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_class_names = [class_names[class_index] for class_index in predicted_classes]\n",
    "\n",
    "print(\"Predicted class names:\", predicted_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feb880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of vectors to store: 4\n",
      "Enter the size of each vector: 4\n",
      "Enter the vectors (each element separated by space):\n",
      "Enter vector 1: 1 1 -1 1\n",
      "Enter vector 2: 1 -1 1 1\n",
      "Enter vector 3: -1 1 1 -1\n",
      "Enter vector 4: 1 1 1 1\n",
      "Original Vector: [1, 1, -1, 1]\n",
      "Recalled Vector: [1. 1. 1. 1.]\n",
      "\n",
      "Original Vector: [1, -1, 1, 1]\n",
      "Recalled Vector: [1. 1. 1. 1.]\n",
      "\n",
      "Original Vector: [-1, 1, 1, -1]\n",
      "Recalled Vector: None\n",
      "\n",
      "Original Vector: [1, 1, 1, 1]\n",
      "Recalled Vector: [1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HopfieldNetwork:\n",
    "    def __init__(self, num_vectors, vector_size):\n",
    "        \"\"\"\n",
    "        Initialize the Hopfield Network.\n",
    "        :param num_vectors: Number of vectors to store\n",
    "        :param vector_size: Size of each vector\n",
    "        \"\"\"\n",
    "        self.num_vectors = num_vectors\n",
    "        self.vector_size = vector_size\n",
    "        self.weights = np.zeros((vector_size, vector_size))\n",
    "\n",
    "    def train(self, vectors):\n",
    "        \"\"\"\n",
    "        Train the Hopfield Network with the given vectors.\n",
    "        :param vectors: List of vectors to store\n",
    "        \"\"\"\n",
    "        for vec in vectors:\n",
    "            vec = np.array(vec).reshape(-1,1)\n",
    "            self.weights += np.dot(vec, vec.T)\n",
    "            np.fill_diagonal(self.weights, 0)\n",
    "            # Setting the diagonal elements of the weight matrix to zero to prevent self-connections.\n",
    "\n",
    "    def recall(self, input_vector, max_iterations=100):\n",
    "        \"\"\"\n",
    "        Recall a stored vector based on the input.\n",
    "        :param input_vector: Input vector to recall\n",
    "        :param max_iterations: Maximum number of iterations for convergence\n",
    "        :return: Recalled vector\n",
    "        \"\"\"\n",
    "        input_vector = np.array(input_vector).reshape(-1, 1)\n",
    "        for _ in range(max_iterations):\n",
    "            output_vector = np.sign(np.dot(self.weights, input_vector))\n",
    "            if np.array_equal(output_vector, input_vector):  # means already this vector or pattern are stored so it recalled\n",
    "                return output_vector.flatten()\n",
    "            input_vector = output_vector\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get user input for number of vectors and vector size\n",
    "    num_vectors = int(input(\"Enter the number of vectors to store: \"))\n",
    "    vector_size = int(input(\"Enter the size of each vector: \"))\n",
    "    \n",
    "    # Initialize the Hopfield Network\n",
    "    hopfield_net = HopfieldNetwork(num_vectors, vector_size)\n",
    "    \n",
    "    # Get user input for vectors\n",
    "    vectors = []\n",
    "    print(\"Enter the vectors (each element separated by space):\")\n",
    "    for i in range(num_vectors):\n",
    "        vec = list(map(int, input(f\"Enter vector {i+1}: \").split()))\n",
    "        vectors.append(vec)\n",
    "    \n",
    "    # Train the Hopfield Network with the vectors\n",
    "    hopfield_net.train(vectors)\n",
    "    \n",
    "    # Recall stored vectors\n",
    "    for vec in vectors:\n",
    "        recalled_vec = hopfield_net.recall(vec)\n",
    "        print(\"Original Vector:\", vec)\n",
    "        print(\"Recalled Vector:\", recalled_vec)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95c2308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal vector [-1, -1, 1, 1]\n",
      "recalled vector [-1. -1.  1.  1.]\n",
      "\n",
      "orignal vector [1, 1, -1, -1]\n",
      "recalled vector [ 1.  1. -1. -1.]\n",
      "\n",
      "orignal vector [-1, 1, -1, 1]\n",
      "recalled vector [-1.  1. -1.  1.]\n",
      "\n",
      "orignal vector [1, -1, 1, -1]\n",
      "recalled vector [ 1. -1.  1. -1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Hopfield:\n",
    "    def __init__(self,num_vectors , vector_size):\n",
    "        \n",
    "        self.num_vectors=num_vectors\n",
    "        self.vector_size=vector_size\n",
    "        self.wts = np.zeros((vector_size,vector_size))\n",
    "        \n",
    "        \n",
    "    def train(self,vectors):\n",
    "        for vec in vectors:\n",
    "            vec=np.array(vec).reshape(-1,1)\n",
    "            self.wts += np.dot(vec,vec.T)\n",
    "            np.fill_diagonal(self.wts,0)\n",
    "            \n",
    "    def recall(self,input_vector , epochs=100):\n",
    "        ip_vec = np.array(input_vector).reshape(-1,1)\n",
    "        for _ in range(epochs):\n",
    "            op_vec = np.sign(np.dot(self.wts, ip_vec))  # Corrected reference to ip_vec\n",
    "\n",
    "            if np.array_equal(op_vec,ip_vec):\n",
    "                return op_vec.flatten()\n",
    "            ip_vec=op_vec\n",
    "        return None\n",
    "    \n",
    "#example usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_vectors=4\n",
    "    vector_size=4\n",
    "    \n",
    "    hop_net = Hopfield(num_vectors,vector_size)\n",
    "    \n",
    "    vectors = [[1,-1,1,-1],[-1,1,-1,1],[1,1,-1,-1],[-1,-1,1,1]] \n",
    "    \n",
    "    test_vectors = [[-1,-1,1,1] , [1,1,-1,-1] ,[-1,1,-1,1],[1,-1,1,-1]]\n",
    "              \n",
    "    hop_net.train(vectors)\n",
    "    \n",
    "    for vec in test_vectors:\n",
    "        recalled_vec = hop_net.recall(vec)\n",
    "        print(\"orignal vector\",vec)\n",
    "        print(\"recalled vector\",recalled_vec)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6af35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
